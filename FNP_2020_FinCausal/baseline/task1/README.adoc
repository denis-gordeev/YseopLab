Task 1 Baseline
---------------

For task 1, we provide a baseline model based on BERT.

The data available in the *baseline/task1/data* repository is the exact partition of the `data/fnp2020-fincausal-task1.csv` file we used to train and evaluate the baseline.
The preprocessing and splitting process can be reproduced running *`baseline/task1/task1_preprocess.py`* script from root.


Usage
~~~~~

* Run *`baseline/task1/task1_baseline.py`*


Results
~~~~~~~

Results are based on evaluation on the Trial data. Note that results may vary depending on the hardware used.


.Task 1 GPU Baseline Results
[options="header"]
|===============================================
|GPU |RAM |CUDA|Precision |Recall |F1
|GeForce GTX 1070 | 8 GB | 10.2 |0.9526      |0.9521      |0.9523
|GeForce RTX 2060 |6 GB | 10.1 |0.9518 |0.9490 |0.9503
|===============================================



References
~~~~~~~~~~

* The model was inspired by https://github.com/huggingface/transformers/[huggingface/transformers^]
* The data preparation was inspired by https://appliedmachinelearning.blog/2019/03/04/state-of-the-art-text-classification-using-bert-model-predict-the-happiness-hackerearth-challenge/[State-of-the-Art Text Classification using BERT model^]